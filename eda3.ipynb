{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22093\n",
      "19540\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data\\wine_cleared.csv')\n",
    "#print(data['country'].value_counts())\n",
    "data['is_france'] = data['country'].apply(lambda x: 1 if x == 'France' else 0)\n",
    "data['is_italy'] = data['country'].apply(lambda x: 1 if x == 'Italy' else 0)\n",
    "print(data['is_france'].sum())\n",
    "print(data['is_italy'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39781\n",
      "0         2013.0\n",
      "1         2011.0\n",
      "2         2013.0\n",
      "3         2013.0\n",
      "4         2012.0\n",
      "           ...  \n",
      "129966    2013.0\n",
      "129967    2004.0\n",
      "129968    2013.0\n",
      "129969    2012.0\n",
      "129970    2012.0\n",
      "Name: year, Length: 129971, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "regex = '\\d{4}' # регулярное выражение для нахождения чисел\n",
    "data['year'] = data['title'].str.findall(regex).str.get(0)\n",
    "data['year2'] = data['title'].str.findall(regex).str.get(0)\n",
    "data['year'] = pd.to_numeric(data['year'])\n",
    "data['old_wine'] = data['year'].apply(lambda x: 1 if x < 2010 else 0)\n",
    "print(data['old_wine'].sum())\n",
    "#data['year'] = pd.to_datetime(data['year'], errors = 'coerce')\n",
    "\n",
    "print(data['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                           Etna\n",
      "1                          Douro\n",
      "2              Willamette Valley\n",
      "3            Lake Michigan Shore\n",
      "4              Willamette Valley\n",
      "                   ...          \n",
      "129966    Erben Müller-Burggraef\n",
      "129967                    Oregon\n",
      "129968                    Alsace\n",
      "129969                    Alsace\n",
      "129970                    Alsace\n",
      "Name: title, Length: 129971, dtype: object\n"
     ]
    }
   ],
   "source": [
    "regex = '\\(([^()]+)\\)'\n",
    "result = data['title'].str.findall(regex).str.get(0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   country  population\n",
      "24   Italy  59,097,904\n",
      "                                                    title   population\n",
      "0                       Nicosia 2013 Vulkà Bianco  (Etna)   59,097,904\n",
      "1           Quinta dos Avidagos 2011 Avidagos Red (Douro)   10,347,892\n",
      "2           Rainstorm 2013 Pinot Gris (Willamette Valley)  333,022,386\n",
      "3       St. Julian 2013 Reserve Late Harvest Riesling ...  333,022,386\n",
      "4       Sweet Cheeks 2012 Vintner's Reserve Wild Child...  333,022,386\n",
      "...                                                   ...          ...\n",
      "129966  Dr. H. Thanisch (Erben Müller-Burggraef) 2013 ...   83,129,285\n",
      "129967                  Citation 2004 Pinot Noir (Oregon)  333,022,386\n",
      "129968  Domaine Gresser 2013 Kritt Gewurztraminer (Als...   68,035,000\n",
      "129969      Domaine Marcel Deiss 2012 Pinot Gris (Alsace)   68,035,000\n",
      "129970  Domaine Schoffit 2012 Lieu-dit Harth Cuvée Car...   68,035,000\n",
      "\n",
      "[129972 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "country_population = pd.read_csv('data\\country_population.csv', sep=';')\n",
    "print(country_population[country_population['country']=='Italy'])\n",
    "df = data.join(country_population.set_index('country'), on='country')\n",
    "print(df.loc[:,['title','population']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0 country                                        description   \n",
      "94          94      US  Barrel notes are prominent, with aromas of Cre...  \\\n",
      "\n",
      "                                designation  points  price    province   \n",
      "94  Grand Klasse Reserve Lawrence Vineyards      88   22.0  Washington  \\\n",
      "\n",
      "                region_1       taster_name taster_twitter_handle   \n",
      "94  Columbia Valley (WA)  Sean P. Sullivan         @wawinereport  \\\n",
      "\n",
      "                                                title   variety winery   \n",
      "94  Gård 2014 Grand Klasse Reserve Lawrence Vineya...  Viognier   Gård  \\\n",
      "\n",
      "    is_france  is_italy    year  old_wine       area  \n",
      "94          0         0  2014.0         0  9372610.0  \n"
     ]
    }
   ],
   "source": [
    "country_area = pd.read_csv('data\\country_area.csv', sep=';')\n",
    "#print(country_area)\n",
    "df2 = data.join(country_area.set_index('country'), on='country')\n",
    "print(df2[df2['title']=='Gård 2014 Grand Klasse Reserve Lawrence Vineyards Viognier (Columbia Valley (WA))'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1144\n"
     ]
    }
   ],
   "source": [
    "# инициализируем информацию о звонках\n",
    "calls_list = [\n",
    "    [460, '2013-12-17 04:55:39', '2013-12-17 04:55:44', '2013-12-17 04:55:45'],\n",
    "    [12, '2013-12-16 20:03:20', '2013-12-16 20:03:22', '2013-12-16 20:07:13'],\n",
    "    [56, '2013-12-16 20:03:20', '2013-12-16 20:03:20', '2013-12-16 20:05:04'],\n",
    "    [980, '2013-12-16 20:03:20','2013-12-16 20:03:27', '2013-12-16 20:03:29'],\n",
    "    [396, '2013-12-16 20:08:27', '2013-12-16 20:08:28','2013-12-16 20:12:03'],\n",
    "    [449, '2013-12-16 20:03:20', '2013-12-16 20:03:25','2013-12-16 20:05:00'],\n",
    "    [397, '2013-12-16 20:08:25', '2013-12-16 20:08:27', '2013-12-16 20:09:59'],\n",
    "    [398, '2013-12-16 20:01:23', '2013-12-16 20:01:23', '2013-12-16 20:04:58'],\n",
    "    [452, '2013-12-16 20:03:20', '2013-12-16 20:03:21','2013-12-16 20:04:55'],\n",
    "    [440, '2013-12-16 20:03:20', '2013-12-16 20:04:26', '2013-12-16 20:04:32']\n",
    "]\n",
    "\n",
    "calls = pd.DataFrame(calls_list, columns = ['client_id',  'agent_date', 'created_at' ,'end_date'])\n",
    "\n",
    "# преобразовываем признаки в формат datetime для удобной работы\n",
    "\n",
    "calls['agent_date'] = pd.to_datetime(calls['agent_date'])\n",
    "calls['created_at'] = pd.to_datetime(calls['created_at'])\n",
    "calls['end_date'] = pd.to_datetime(calls['end_date'])\n",
    "#print(calls)\n",
    "calls['duration'] = (calls['end_date'] - calls['created_at']).dt.seconds\n",
    "calls['time_connection'] = (calls['created_at'] - calls['agent_date']).dt.seconds\n",
    "calls['is_connection'] = calls['duration'].apply(lambda x: 1 if x>10 else 0)\n",
    "calls['time_diff'] = (calls['end_date'] - calls['agent_date']).dt.seconds\n",
    "print(calls['time_diff'].sum())\n",
    "calls = calls.drop(columns=['agent_date', 'created_at' ,'end_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98627.0\n"
     ]
    }
   ],
   "source": [
    "#ddd = pd.to_datetime('2022-01-12 00:00:00')\n",
    "data['year2'] = pd.to_datetime(data['year2'], errors = 'coerce')\n",
    "#data['const'] = pd.to_datetime('2022-01-12 00:00:00')\n",
    "data['years_diff'] = (pd.to_datetime('2022-01-12') - data['year2']).dt.days\n",
    "print(data['years_diff'].max())\n",
    "#print(data.loc[:,['const','year']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce \n",
    "clothing_list = [\n",
    "    ['xxs', 'dress'],\n",
    "    ['xxs', 'skirt'],\n",
    "    ['xs', 'dress'],\n",
    "    ['s', 'skirt'],\n",
    "    ['m', 'dress'],\n",
    "    ['l', 'shirt'],\n",
    "    ['s', 'coat'],\n",
    "    ['m', 'coat'],\n",
    "    ['xxl', 'shirt'],\n",
    "    ['l', 'dress']\n",
    "]\n",
    "\n",
    "clothing = pd.DataFrame(clothing_list, columns = ['size',  'type'])\n",
    "\n",
    "# создаем объект OrdinalEncoder, col - имя столбца, mapping - словарь с описанием кодировки\n",
    "ord_encoder = ce.OrdinalEncoder(mapping=[{\n",
    "\t'col': 'size',\n",
    "\t'mapping': {'xxs': 1, 'xs': 2, 's': 3, \n",
    "                'm': 4, 'l': 5, 'xxl': 6}\n",
    "}])\n",
    "# применяем трансформацию к столбцу\n",
    "data_bin = ord_encoder.fit_transform(clothing[['size']])\n",
    "# добавляем результат к исходному DataFrame\n",
    "clothing = pd.concat([clothing, data_bin], axis=1)\n",
    "print(clothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder(cols=['type'], use_cat_names=True)\n",
    "type_bin = encoder.fit_transform(clothing['type'])\n",
    "clothing = pd.concat([clothing, type_bin], axis=1)\n",
    "print(clothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129971, 20)\n",
      "(129971, 40)\n"
     ]
    }
   ],
   "source": [
    "encoder = ce.OneHotEncoder(cols=['taster_name'], use_cat_names=True)\n",
    "type_bin = encoder.fit_transform(data['taster_name'])\n",
    "dfa = pd.concat([data, type_bin], axis=1)\n",
    "print(data.shape)\n",
    "print(dfa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129971, 20)\n",
      "(129971, 26)\n"
     ]
    }
   ],
   "source": [
    "bin_encoder = ce.BinaryEncoder(cols=['country']) # указываем столбец для кодирования\n",
    "type_bin = bin_encoder.fit_transform(data['country'])\n",
    "dfc = pd.concat([data, type_bin], axis=1)\n",
    "print(data.shape)\n",
    "print(dfc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129971, 20)\n",
      "(129971, 25)\n"
     ]
    }
   ],
   "source": [
    "bin_encoder = ce.BinaryEncoder(cols=['taster_twitter_handle']) # указываем столбец для кодирования\n",
    "type_bin = bin_encoder.fit_transform(data['taster_twitter_handle'])\n",
    "dfc = pd.concat([data, type_bin], axis=1)\n",
    "print(data.shape)\n",
    "print(dfc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    product  price payment_type  product  payment_type_Mastercard   \n",
      "0  Product1   1200   Mastercard        1                        1  \\\n",
      "1  Product2   3600         Visa        2                        0   \n",
      "2  Product3   7500         Amex        3                        0   \n",
      "\n",
      "   payment_type_Visa  payment_type_Amex  \n",
      "0                  0                  0  \n",
      "1                  1                  0  \n",
      "2                  0                  1  \n"
     ]
    }
   ],
   "source": [
    "list_of_dicts = [\n",
    " {'product': 'Product1', 'price': 1200, 'payment_type': 'Mastercard'},\n",
    " {'product': 'Product2', 'price': 3600, 'payment_type': 'Visa'},\n",
    " {'product': 'Product3', 'price': 7500, 'payment_type': 'Amex'}\n",
    "]\n",
    "df = pd.DataFrame(list_of_dicts)\n",
    "ord_encoder = ce.OrdinalEncoder(mapping=[{\n",
    "\t'col': 'product',\n",
    "\t'mapping': {'Product1': 1, 'Product2': 2, 'Product3': 3}\n",
    "}])\n",
    "data_bin = ord_encoder.fit_transform(df[['product']])\n",
    "# добавляем результат к исходному DataFrame\n",
    "df = pd.concat([df, data_bin], axis=1)\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=['payment_type'], use_cat_names=True)\n",
    "type_bin = encoder.fit_transform(df['payment_type'])\n",
    "df = pd.concat([df, type_bin], axis=1)\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
